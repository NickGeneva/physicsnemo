---
description: Every model requires comprehensive CI tests - constructor/attributes, non-regression with reference data, and checkpoint loading - following test_layers_unet_block.py template.
alwaysApply: false
---

When creating new models or refactoring existing models, or adding tests for models, rule MOD-008 must be followed. Explicitly reference "Following rule MOD-008" when implementing tests. For example: "Following rule MOD-008, which states that every model in a module file `my_model_name.py` in `physicsnemo/nn` or `physicsnemo/models` must have corresponding tests in `test/models/test_<my_model_name>.py`, ..."

## MOD-008: Minimal CI testing requirements

**Description:**

Every model in a module file `my_model_name.py` in `physicsnemo/nn` or
`physicsnemo/models` must have corresponding tests in
`test/models/test_<my_model_name>.py`. Tests should roughly follow a similar
template and, three types of tests are required:

1. **Constructor and attribute tests**: Verify model instantiation and all
   public attributes (excluding buffers and parameters).

2. **Non-regression test with reference data**: Instantiate a model, run
   forward pass, and compare outputs against reference data saved in a `.pth`
   file.

3. **Non-regression test from checkpoint**: Load a model from a checkpoint file
   (`.mdlus`) and verify outputs match reference data.

Additional requirements:
- All tests must use `pytest` parameterization syntax
- At least 2 configurations must be tested: one with all default arguments, one
  with non-default arguments. More variations specific to some relevant
  use-cases are also encouraged.
- Test tensors must have realistic shapes (e.g. no singleton dimensions) and
  should be as meaningful and representative of actual use cases as possible.
- All public methods must have the same non-regression tests as the forward
  method
- Simply checking output shapes is NOT sufficient - actual values must be
  compared
- **Critical:** Per MOD-002, it is forbidden to move a model out of the
  experimental stage/directory without these tests

**Rationale:**

Comprehensive tests ensure model correctness and prevent regressions as code
evolves. Non-regression tests with reference data catch subtle numerical changes
that could break reproducibility. Checkpoint tests verify serialization and
deserialization work correctly. Parameterized tests ensure models work across
different configurations. These tests are required before models can graduate
from experimental to production status.

**Example:**

```python
# Good: Following the test_layers_unet_block.py template
import pytest
import torch
from physicsnemo.models import MyModel

def _instantiate_model(cls, seed: int = 0, **kwargs):
    """Helper to create model with reproducible parameters."""
    model = cls(**kwargs)
    gen = torch.Generator(device="cpu")
    gen.manual_seed(seed)
    with torch.no_grad():
        for param in model.parameters():
            param.copy_(torch.randn(param.shape, generator=gen, dtype=param.dtype))
    return model

@pytest.mark.parametrize("device", ["cuda:0", "cpu"])
@pytest.mark.parametrize(
    "config",
    ["default", "custom"],
    ids=["with_defaults", "with_custom_args"]
)
def test_my_model_non_regression(device, config):
    """Test model forward pass against reference output."""
    # Setup model configuration
    if config == "default":
        model = _instantiate_model(MyModel, input_dim=64, output_dim=32)
    else:
        model = _instantiate_model(
            MyModel,
            input_dim=64,
            output_dim=32,
            hidden_dim=256,
            dropout=0.1
        )

    model = model.to(device)

    # Test constructor and attributes
    assert model.input_dim == 64
    assert model.output_dim == 32
    if config == "custom":
        assert model.hidden_dim == 256
        assert model.dropout == 0.1

    # Load reference data (meaningful shapes, no singleton dimensions)
    data = torch.load(f"test/models/data/my_model_{config}_v1.0.pth")
    x = data["x"].to(device)  # Shape: (4, 64), not (1, 64)
    out_ref = data["out"].to(device)

    # Run forward and compare
    out = model(x)
    assert torch.allclose(out, out_ref, atol=1e-5, rtol=1e-5)

@pytest.mark.parametrize("device", ["cuda:0", "cpu"])
def test_my_model_from_checkpoint(device):
    """Test loading model from checkpoint and verify outputs."""
    model = physicsnemo.Module.from_checkpoint(
        "test/models/data/my_model_default_v1.0.mdlus"
    ).to(device)

    # Test attributes
    assert model.input_dim == 64
    assert model.output_dim == 32

    # Load reference and verify
    data = torch.load("test/models/data/my_model_default_v1.0.pth")
    x = data["x"].to(device)
    out_ref = data["out"].to(device)
    out = model(x)
    assert torch.allclose(out, out_ref, atol=1e-5, rtol=1e-5)
```

**Anti-pattern:**

```python
# WRONG: Only testing output shapes
def test_my_model_bad(device):
    model = MyModel(input_dim=64, output_dim=32).to(device)
    x = torch.randn(4, 64).to(device)
    out = model(x)
    assert out.shape == (4, 32)  # NOT SUFFICIENT!

# WRONG: Using singleton dimensions in test data
def test_my_model_bad(device):
    x = torch.randn(1, 1, 64)  # WRONG: Trivial shapes hide bugs

# WRONG: No parameterization
def test_my_model_bad():
    model = MyModel(input_dim=64, output_dim=32)  # Only tests defaults

# WRONG: No checkpoint loading test
# (Missing test_my_model_from_checkpoint entirely)
```
