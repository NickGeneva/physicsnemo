---
description: Forbids changing model signatures without backward compatibility via version bumps, __supported_model_checkpoint_version__, and _backward_compat_arg_mapper implementations.
alwaysApply: false
---

When modifying existing production models, rule MOD-007 must be strictly followed. Explicitly reference "Following rule MOD-007" when explaining version changes. For example: "Following rule MOD-007, which states that for any model in `physicsnemo/nn` or `physicsnemo/models`, it is strictly forbidden to change the signature of `__init__`, any public method, or any public attribute without maintaining backward compatibility, incrementing __model_checkpoint_version__ and adding _backward_compat_arg_mapper to handle parameter rename..."

## MOD-007: Backward compatibility

**Description:**

For any model in `physicsnemo/nn` or `physicsnemo/models`, it is strictly
forbidden to change the signature of `__init__`, any public method, or any
public attribute without maintaining backward compatibility. This includes:
- Adding new required parameters
- Removing parameters
- Renaming parameters
- Changing parameter types
- Changing return types

If a signature change is absolutely necessary, the developer must:
1. Add a backward compatibility mapping in the model class
2. Increment the model version number
3. Maintain support for the old API for at least 2 release cycles
4. Add deprecation warnings for the old API

**Rationale:**

PhysicsNeMo is used in production environments and research code where
unexpected API changes can break critical workflows. Maintaining backward
compatibility ensures that users can upgrade to new versions without their code
breaking. Version numbers and compatibility mappings provide a clear migration
path when changes are necessary.

**Example:**

```python
from typing import Any, Dict, Optional

# Good: Adding optional parameter with default value (backward compatible)
class MyModel(Module):
    __model_checkpoint_version__ = "2.0"
    __supported_model_checkpoint_version__ = {
        "1.0": "Loading checkpoint from version 1.0 (current is 2.0). Still supported."
    }

    def __init__(
        self,
        input_dim: int,
        output_dim: int,
        dropout: float = 0.0,  # New parameter with default
        new_feature: bool = False  # New parameter with default
    ):
        super().__init__(meta=MyModelMetaData())
        # ... implementation

# Good: Proper backward compatibility when parameter must be renamed
class MyModel(Module):
    __model_checkpoint_version__ = "2.0"
    __supported_model_checkpoint_version__ = {
        "1.0": (
            "Loading MyModel checkpoint from version 1.0 (current is 2.0). "
            "Parameter 'hidden_dim' has been renamed to 'hidden_size'. "
            "Consider re-saving to upgrade to version 2.0."
        )
    }

    @classmethod
    def _backward_compat_arg_mapper(
        cls, version: str, args: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Map arguments from older versions to current version format."""
        # Call parent class method first
        args = super()._backward_compat_arg_mapper(version, args)

        if version == "1.0":
            # Map old parameter name to new name
            if "hidden_dim" in args:
                args["hidden_size"] = args.pop("hidden_dim")

            # Remove deprecated parameters that are no longer used
            if "legacy_param" in args:
                _ = args.pop("legacy_param")

        return args

    def __init__(
        self,
        input_dim: int,
        output_dim: int,
        hidden_size: int = 128,  # New name (was 'hidden_dim' in v1.0)
    ):
        super().__init__(meta=MyModelMetaData())
        self.hidden_size = hidden_size
        # ... implementation
```

**Anti-pattern:**

```python
# WRONG: Changing parameter name without backward compatibility
class MyModel(Module):
    __model_checkpoint_version__ = "2.0"
    # Missing: __supported_model_checkpoint_version__ and _backward_compat_arg_mapper

    def __init__(self, input_dim: int, hidden_size: int):  # Renamed from hidden_dim
        super().__init__(meta=MyModelMetaData())
        # WRONG: Old checkpoints with 'hidden_dim' will fail to load!

# WRONG: Not calling super() in _backward_compat_arg_mapper
class MyModel(Module):
    @classmethod
    def _backward_compat_arg_mapper(cls, version: str, args: Dict[str, Any]) -> Dict[str, Any]:
        # WRONG: Missing super()._backward_compat_arg_mapper(version, args)
        if version == "1.0":
            if "hidden_dim" in args:
                args["hidden_size"] = args.pop("hidden_dim")
        return args
```
